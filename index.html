<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Workshop on Cognitive Architectures</title>

    <!-- css -->
    <link rel="stylesheet" href="bower_components/bootstrap/dist/css/bootstrap.min.css">
    <link rel="stylesheet" href="bower_components/ionicons/css/ionicons.min.css">
    <link rel="stylesheet" href="assets/css/main.css">
</head>
<body data-spy="scroll" data-target="#site-nav">
    <nav id="site-nav" class="navbar navbar-fixed-top navbar-custom">
        <div class="container">
            <div class="navbar-header">

                <!-- logo -->
                <div class="site-branding">
                    <a class="logo" href="index.html">
                        
                        <!-- logo image  -->
                        <!-- <img src="assets/images/logo.png" alt="Logo"> -->
                        CogArch
                    </a>
                </div>

                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar-items" aria-expanded="false">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>

            </div><!-- /.navbar-header -->

            <div class="collapse navbar-collapse" id="navbar-items">
                <ul class="nav navbar-nav navbar-right">

                    <!-- navigation menu -->
                    <li class="active"><a data-scroll href="#about">About</a></li>
                    <li><a data-scroll href="#about">Call for Contributions</a></li>
                    <li><a data-scroll href="#speakers">Speakers</a></li>         
                    <li><a data-scroll href="#program">Program</a></li>
                    <li><a data-scroll href="#prev">Past Editions</a></li>
                    <li><a data-scroll href="#org">Organizers</a></li>
                
                </ul>
            </div>
        </div><!-- /.container -->
    </nav>

    <header id="site-header" class="site-header valign-center"> 
        <div class="intro">

            <p>June 30<sup>th</sup> 2024, Buenos Aires, Argentina</p>

            <h1>CogArch 2024</h1>            
            <h1>8<sup>th</sup> Workshop on Cognitive Architectures</h1>
			
			<h2 style="color: #FF7A59"><em><strong>Bits and Brains: Transformative AI Approaches to Hardware Design</strong></em></h2>
            
            <p>In conjunction with the 51<sup>st</sup> International Symposium<br>
                on Computer Architecture (ISCA 2024)</p>
            
            <a class="btn btn-white" data-scroll href="#about">Contribute Now</a>

            <a class="btn btn-white" data-scroll href="#registration">Register Now</a>
        
        </div>
    </header>

    <section id="about" class="section about">
        <div class="container">
            <div class="row">
                <div class="col-sm-6">

                    <h3 class="section-title">About</h3>
                    
       			             <p>
					    Artificial Intelligence (AI) and Machine Learning (ML) techniques have become the <em>de facto</em> solution to drive human
					    progress and more specifically, automation. In the last few years, the world’s economy has been gravitating towards the AI/ML
					    domain (from industrial and scientific perspectives) and the expectation of growth has only been increasing with the rapid rate of 
					    innovation and commercial deployments.
				    </p>
					<p>
					   Over the past 7 editions, the CogArch workshop has brought together experts and knowledge on the most novel design ideas for cognitive systems. 
					   This workshop capitalizes on the synergy between industrial and academic efforts in order to provide a better understanding of cognitive systems 
					   and key concepts of their design. In particular, while previous editions of the workshop have attempted to address co-designed hardware-software 
					   architectures that enable the latest advancements in machine learning, this edition focuses on applying state-of-the-art machine learning models 
					   towards realizing novel processor architectures and design. Architecting, designing, verifying and manufacturing commercial-grade processor requires 
					   hundreds of highly skilled designers, complex toolflows and a time-to-market of several months to years, and leveraging AI techniques at various 
					   stages in the design cycle can serve to significantly ease these constraints.
				    </p>
					<p> 
					The CogArch workshop has already had seven successful editions, bringing together experts and knowledge on the most novel
					design ideas for cognitive systems. This workshop capitalizes on the synergy between industrial and academic efforts in order to provide
					a better understanding of cognitive systems and key enablers of their design.
                    		   </p>

                    <h3 class="section-title multiple-title">Call for Papers</h3>

                    		   <p>
		    			Hardware and software design considerations are gravitating towards AI applications, as those have been proven extremely useful in a wide variety of 
					fields, from edge computing in autonomous cars, to cloud-based computing for personalized medicine. Recent efforts to utilize AI for hardware design 
					have been gaining traction. AI models have been shown to be effective in tackling complex challenges in the EDA world when applied to automatic 
					place-and-route, design of novel architectures, leveraging new material/packaging technologies or even optimizing manufacturing processes.

				   </p>
                    		   <p>
		    			The CogArch workshop solicits formative ideas and new product offerings in the general space of AI systems that are applied towards designing of 
					next generation processing systems, at every stage of conceptualization, design, testing, verification and manufacturing.
				    </p>

					<strong>Topics of interest include (but are not limited to):</strong>
                    <ul class="list-arrow-right">
			<li>Application of AI models towards hardware design</li>
			<li>AI-enabled architecture design and exploration</li>
			<li>AI for efficient EDA optimizations, place-and-route</li>
			<li>AI-enabled optimizations for compilers, firmware and middleware</li>
			<li>AI for test bench generation for hardware</li>
			<li>AI techniques for leveraging emerging device technologies, 2.5D/3D stacking, chiplet architectures, novel packaging technologies</li>
			<li>AI/ML for fast system modeling and simulation</li>
			<li>AI for improving efficiency and coverage of verification methodologies</li>
			<li> Demonstrations (live or recorded) showcasing prototypes, tools and methodologies for AI-inspired hardware design </li>
                    </ul>

                </div><!-- /.col-sm-6 -->

                <div class="col-sm-6">

					<p>
			The workshop will consist of regular presentations and/or prototype demonstrations by authors of
			selected submissions. In addition, it will include invited keynotes by eminent researchers as well as
			interactive panel discussions to kindle further interest in these research topics. Submissions will be
			reviewed by a Workshop Selection Committee comprising of experts from industry and academia.
			Keeping in mind the cross-disciplinary nature of this workshop, this committee will consist of
			researchers with diverse interests covering the spectrum of design automation, testing/verification,
			architecture, and machine learning. 
			<!--
			As this workshop is to be co-located with the very first edition of
			ISCA to be held in South America, we plan to invite keynote speakers, panelists and selection committee
			members from prominent universities and industries from this region.
			-->
                    </p>
                    
                    <p>
                    Submitted manuscripts must be in English of <strong>up to 2 pages</strong> (with same
                    <a href="https://www.iscaconf.org/isca2023/submit/guidelines.php" target="_blank">formatting guidelines as main 
                    conference</a>). Submissions should be submitted to the following
					<strong><a href="https://easychair.org/my/conference?conf=cogarch2024" target="_blank">link</a></strong> by
					<strong><s>April 11<sup>th</sup></s> <font color="red">April 20<sup>th</sup>, 2024</font></strong>.
                    <br>
                    If you have questions regarding submission, please contact us:
                    <a href="mailto:info@cogarchworkshop.org">info@cogarchworkshop.org</a>
                    </p>
			<!--
                    <h3 class="section-title multiple-title">Call for Prototype Demonstrations</h3>

                    <p>
                    CogArch will feature a session where researchers can showcase innovative prototype demonstrations or 
                    <i>proof-of-concept</i> designs in the cognitive architecture space. Examples of such demonstrations may include (but are 
                    not limited to):
                    
                    <ul class="list-arrow-right">
                        <li>Custom ASIC or FPGA-based demonstrations of machine learning, cognitive or neuromorphic architectures.</li>
                        <li>Innovative implementations of state-of-the-art cognitive algorithms/applications, and the underlying 
                            software-hardware co-design techniques.</li>
                        <li>Demonstration of end-to-end cognitive systems comprising of edge devices backed by a cloud computing 
                            infrastructure.</li>
                        <li>Novel designs showcasing the adoption of emerging technologies for the design of cognitive systems.</li>
                        <li>Tools or frameworks to aid analysis, simulation and design of cognitive systems.</li>
                    </ul>

                    Submissions for the demonstration session may be made in the form of a 2-page manuscript highlighting key features and 
                    innovations of the prototype demonstration. Proposals accepted for demonstration during the workshop can be accompanied 
                    by a poster/short presentation. Authors should explicitly indicate that the submission is for <strong>prototype 
                    demonstration</strong> at submission time.
                    </p>
			-->
                    <h3 class="section-title multiple-title">Important Dates</h3>
                      
                    <p>
					<ul class="list-arrow-right">
						<li>Paper submission deadline: <s>April 11<sup>th</sup></s> <strong><font color="red">April 20<sup>th</sup>, 2024 (EXTENDED!)</font></strong></li>
						<li>Notification of acceptance: April 25<sup>th</sup>, 2024</li>
						<li>Camera-ready submission deadline: June 7<sup>th</sup>, 2024</li>
						<li>Workshop date: June 30<sup>th</sup>, 2024</li>
					</ul>
                    </p>

                    <h3 class="section-title multiple-title">Program Committee</h3>

                    <p>
					<ul class="list-arrow-right">
                        <li>Karthik Swaminathan, IBM Research</li>
			<li>Subhankar Pal, IBM Research</li>
			<li>Aporva Amarnath, IBM Research</li>
			<li>Ananda Samajdar, IBM Research</li>
					</ul>
                    </p>
					
			<!--
					<h3 class="section-title multiple-title">YouTube Channel</h3>
					
					<p>
					<iframe width="392" height="220" src="https://www.youtube.com/embed/videoseries?list=PLTo_S756axY7US3wNyqvHvucGi2XchnwQ"
					title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope;
					picture-in-picture; web-share" allowfullscreen></iframe>
					</p>
			-->
		
                </div><!-- /.col-sm-6 -->
            </div><!-- /.row -->
        </div><!-- /.container -->
    </section>

    <section id="important" class="section bg-image-1 facts text-center">
        <div class="container">
            <div class="row">
                <div class="col-sm-4">

                    <i class="ion-ios-calendar"></i>
                    <h3>Paper Submission Deadline<br>April 11<sup>th</sup>, 2024</h3>
                
                </div>
                <div class="col-sm-4">

                    <i class="ion-ios-calendar"></i>
                    <h3>Notification Date<br>April 25 <sup>th</sup>, 2024</h3>
                
                </div>
                <div class="col-sm-4">

                    <i class="ion-ios-calendar"></i>
                    <h3>Workshop Date<br>June 30<sup>th</sup>, 2024</h3>
                
                </div>
            </div><!-- row -->
        </div><!-- container -->
    </section>

    <section id="speakers" class="section speakers">
        <div class="container">
			
            <div class="row">
                <div class="col-md-12">
                    <h3 class="section-title">Invited Speakers:</h3>    
                </div>
            </div>

            <div class="row">
                <div class="col-md-2">
                    <div class="speaker">
                        <figure>
                            <img alt="" class="img-responsive center-block" src="assets/images/speakers/azalia.jpg" style="border-radius:50%">
                        </figure>
                    </div>
                </div>

                <div class="col-sm-10">
					<h3>Scaling Intelligence</h3>
					<h4><a href="http://azaliamirhoseini.com" target="_blank"> Azalia Mirhoseini (Assistant Professor, Stanford University)</a></h4>
					<p>
          	  		</p> 
				</div>
            </div>
			
            <div class="row">
                <div class="col-md-2">
                    <div class="speaker">
                        <figure>
                            <img alt="" class="img-responsive center-block" src="assets/images/speakers/adolfy.jpg" style="border-radius:50%">
                        </figure>
                    </div>
                </div>

                <div class="col-sm-10">
					<h3>Modeling and Simulation (ModSim) in the AI Era</h3>
					<h4><a href="https://www.bnl.gov/staff/ahoisie" target="_blank"> Adolfy Hoisie, (Chair, Systems, Architectures, and Advanced Technologies Department, Brookhaven National Laboratory)</a></h4>
					<p>
					While accurate simulators are essential tools for
					architecture research, design, and development, their practicality is limited
					by an extremely long time-to-solution for realistic architectures and
					applications. The presentation will focus on recent advances aiming at
					developing AI techniques for architecture modeling and simulation (ModSim).  We
					will discuss research aiming at developing machine learning AI/ML techniques
					for architecture simulation with a spectrum of goals from accelerating to using
					AI/ML as an alternative to existing techniques . We will strive to answer key
					questions such as: Is it doable? Is it practical? Is it fast? Is it accurate?
					What is the range of uses? The ability of these methods to cope with
					heterogeneous architectures for complex workflows, and a new frontier of
					applicability to codesign of complex systems in a dynamic regime will be
					discussed.
          	  		</p> 
				</div>
            </div>
			
            <div class="row">
                <div class="col-md-2">
                    <div class="speaker">
                        <figure>
                            <img alt="" class="img-responsive center-block" src="assets/images/speakers/vj.jpg" style="border-radius:50%">
                        </figure>
                    </div>
                </div>

                <div class="col-sm-10">
					<h3> Architecture 2.0: From Concept to Breaking Ground</h3>
					<h4><a href="https://scholar.harvard.edu/vijay-janapa-reddi" target="_blank"> Vijay Janapa Reddi (Associate Professor, Harvard University)</a></h4>
					<p>
          	  		</p> 
				</div>
            </div>
			
<!--
            <div class="row">
                <div class="col-md-2">
                    <div class="speaker">
                        <figure>
                            <img alt="" class="img-responsive center-block" src="assets/images/speakers/suvinay_subramanian.jpg" style="border-radius:50%">
                        </figure>
                    </div>
                </div>

                <div class="col-sm-10">
					<h3>Codesigning Computing Systems for Artificial Intelligence</h3>
					<h4><a href="https://www.linkedin.com/in/suvinay-subramanian-53163b20a/" target="_blank">Suvinay Subramanian
						(Staff Software Engineer - Google)</a></h4>
					<p>
						The rapid advancement of artificial intelligence (AI) has ushered in an era of unprecedented computational demands, necessitating continuous
						innovation in computing systems. In this talk, we will highlight how codesign has been a key paradigm in enabling innovative solutions and
						state-of-the-art performance in Google's AI computing systems, namely Tensor Processing Units (TPUs). We present several codesign case studies
						across different layers of the stack, spanning hardware, systems, software, algorithms, all the way up to the datacenter. We discuss how TPUs
						have made judicious, yet opinionated bets in our design choices, and how these design choices have not only kept pace with the blistering rate
						of change, but also enabled many of the breakthroughs in AI.
          	  		</p> 
				</div>
            </div>
			
            <div class="row">
                <div class="col-md-2">
                    <div class="speaker">
                        <figure>
                            <img alt="" class="img-responsive center-block" src="assets/images/speakers/carlos_costa.jpg" style="border-radius:50%">
                        </figure>
                    </div>
                </div>

                <div class="col-sm-10">
					<h3>Building a Cloud-Native Platform for the Future of AI: Foundation Models</h3>
					<h4><a href="https://www.linkedin.com/in/carlos-h-a-costa-9b9b1a1/" target="_blank">Carlos Costa
						(Principal Research Staff Member - IBM)</a></h4>
					<p>
						Foundation Model is an emerging inflection point in the creation of powerful, very high dimensional data representations, triggered by advances
						in AI. Foundation Models in AI are billion-parameter-scale neural networks, powered by novel architectures which are trained using a technique
						called self-supervision. This new paradigm imposes unprecedented opportunities and challenges across the full computing stack. Hear how IBM Research
						is expanding and realizing the value of Foundation Models, from building a cloud-native supercomputing infrastructure and a simplified, cloud-native
						common stack to train and deploy Foundation Models in an multicloud environment, to applying this full stack to enable advances in natural language
						domain and beyond, including time series and code generation. 
          	  		</p> 
				</div>
            </div>

            <div class="row">
                <div class="col-md-2">
                    <div class="speaker">
                        <figure>
                            <img alt="" class="img-responsive center-block" src="assets/images/speakers/tushar_krishna.jpg" style="border-radius:50%">
                        </figure>
                    </div>
                </div>

                <div class="col-sm-10">
					<h3>Modeling and Mitigating Communication Bottlenecks for Large Model Training at Scale</h3>
					<h4><a href="https://www.linkedin.com/in/tushar-krishna-a60b0970/" target="_blank">Tushar Krishna
						(Associate Professor - Georgia Institute of Technology)</a></h4>
					<p>
						The unprecedented success of large language models (LLMs) &mdash; such as Open AI's GPT-3 and GPT-4, Google's Bard, Meta's LLaMa , Cerebras-GPT and
						others &mdash; is emphasizing the ever-growing demand to efficiently train them. These models leverage billions to trillions of model parameters and
						this trend continues to increase at an unforeseen rate. The large model size makes it impossible for their parameters to fit within a single accelerator
						device, whose memory is usually capped at tens of GBs. Furthermore, even if we succeed to fit the model into a single device, their tremendous compute
						requirement leads to almost impractical training time. For example, GPT-3 consists of 175B parameters and takes 355 GPU-years to train with a single
						NVIDIA V100 GPU. This has led to a growing interest in distributed training, which is the idea of sharding model weights and/or data samples across
						multiple accelerator devices. However, this comes at the expense of communication overhead to exchange gradients and activations, and it has already
						become a key bottleneck for distributed training. We identify that the communication challenge will get exacerbated in future systems that are expected
						to leverage multi-dimensional networks with heterogeneous bandwidths due to diverse fabric technologies (e.g., chiplets, rack-scale, and scaleout).
						We present our recent works on <em>(i)</em> modeling future training platforms to identify such bottlenecks, and <em>(ii)</em> a novel runtime scheduling
						policy to enhance network bandwidth utilization.
          	  		</p> 
				</div>
            </div>
-->
<!--
            <div class="row">
                <div class="col-md-2">
                    <div class="speaker">
                        <figure>
                            <img alt="" class="img-responsive center-block" src="assets/images/speakers/tajana_rosing.jpg" style="border-radius:50%">
                        </figure>
                    </div>
                </div>

                <div class="col-sm-10">
					<h3>End-to-End Learning with Fully Homomorphic Encryption in Memory</h3>
					<h4><a href="https://cseweb.ucsd.edu/~trosing/" target="_blank">Tajana Šimunić Rosing
						(University of California, San Diego)</a></h4>
					<p>
						The increasing amount of data and the growing complexity of problems has resulted in an ever-growing reliance on cloud computing.
						However, many applications, most notably in healthcare, finance or defense, demand security and privacy which today's solutions cannot
						fully address. Fully homomorphic encryption (FHE) elevates the bar of today's solutions by adding confidentiality of data during processing.
						It allows computation on fully encrypted data without the need for decryption, thus fully preserving privacy. To enable processing encrypted
						data at usable levels of classic security, e.g., 128-bit, the encryption procedure introduces noticeable data size expansion &mdash; the
						ciphertext is much bigger than the native aggregate of native data types. In this talk, we present MemFHE which is the first accelerator of
						both client and server for the latest Ring-GSW (Gentry, Sahai, and Waters) based homomorphic encryption schemes using Processing In Memory
						(PIM). PIM alleviates the data movement issues with large FHE encrypted data, while providing in-situ execution and extensive parallelism
						needed for FHE’s polynomial operations. While the client-PIM can homomorphically encrypt and decrypt data, the server-PIM can process
						homomorphically encrypted data without decryption. Our server-PIM is pipelined and is designed to provide flexible bootstrapping, allowing
						two encryption techniques and various FHE security-levels based on the application requirements. We evaluate our design at various security-levels
						and compare it with state-of-the-art CPU implementations for Ring-GSW based FHE. Our system is up to 20k&times; (265&times;) faster than CPU (GPU)
						for FHE arithmetic operations and provides on average 2007&times; higher throughput than the state of the art while implementing learning algorithms
						with FHE.
          	  		</p> 
				</div>
            </div>

            <div class="row">
                <div class="col-md-2">
                    <div class="speaker">
                        <figure>
                            <img alt="" class="img-responsive center-block" src="assets/images/speakers/ro_cammarota.jpg" style="border-radius:50%">
                        </figure>
                    </div>
                </div>

                <div class="col-sm-10">
					<h3>Homomorphic Computing, with a Focus on Hardware-Accelerated Homomorphic Encryption</h3>
					<h4><a href="https://www.intel.com/content/www/us/en/research/researchers/ro-cammarota.html" target="_blank">Rosario Cammarota
						(Intel)</a></h4>
					<p>
						Enabling processing encrypted data elevates the bar of confidentiality in existing security solutions and opens the front to new applications.
						It preserves individuals' privacy and market competitiveness while sustaining societal and economic growth through data sharing, collaboration,
						and artificial intelligence. Homomorphic Encryption (HE) is a unique family of cryptographic methods to process encrypted data. HE applications
						can reduce the risk of third-party data leakage at the processing node while preserving both data ownership and lifecycle. However, the performance
						gap that even the most efficient HE schemes hinder enabling meaningful HE applications and adopting the technology. HE applications can be a million
						times slower than the corresponding unencrypted applications on existing hardware architectures. Other barriers to adoption include the lack of
						development tools to reduce non-recurring engineering costs to build HE applications and the lack of international standards.
						Innovation in hardware architecture is the first step in bridging the performance gap and setting directions to enable meaningful technology adoption.
						In this talk, I will share Intel's innovation from theory to algorithms down to hardware architecture to allow the adoption of processing encrypted
						data with HE. Jointly with Microsoft, our Standards & Industry Organization and academic partners, we develop novel HE platforms comprehensive of
						revolutionary hardware, software libraries, development tools, and applications to make HE technologies accessible, performant, and cost-effective.
						We build an ecosystem that can sustain the exponential growth of HE-based technologies.
          	  		</p> 
				</div>
            </div>

            <div class="row">
                <div class="col-md-2">
                    <div class="speaker">
                        <figure>
                            <img alt="" class="img-responsive center-block" src="assets/images/speakers/hayim_shaul.jpg" style="border-radius:50%">
                        </figure>
                    </div>
                </div>

                <div class="col-sm-10">
					<h3>CircLayer &mdash; Circuit Optimization &amp; Scheduling Made Easy</h3>
					<h4><a href="https://www.linkedin.com/in/hayim-shaul-b2658/?originalSubdomain=il" target="_blank">Hayim Shaul
						(IBM Research)</a></h4>
					<p>
						CircLayer is a circuit abstraction layer part of the HELayers end-to-end framework to write high level fully homomorphic encryption code. CircLayer
						lets the researcher apply optimizations directly on the circuit level. In addition it gives control on scheduling decisions made when executing the
						circuit. This makes CircLayer an ideal choice for researches and developers who develop new optimization and scheduling algorithms.
          	  		</p> 
				</div>
            </div>

            <div class="row">
                <div class="col-md-2">
                    <div class="speaker">
                        <figure>
                            <img alt="" class="img-responsive center-block" src="assets/images/speakers/kevin_barker.jpg" style="border-radius:50%">
                        </figure>
                    </div>
                </div>

                <div class="col-sm-10">
					<h3>Codesigning the Next Generation of Intelligent Computing Systems</h3>
					<h4><a href="https://www.pnnl.gov/people/kevin-j-barker" target="_blank">Kevin Barker
						(Pacific Northwest National Laboratory)</a></h4>
					<p>
						Convergence is driving the emergence of tightly integrated scientific workflows that combine physical simulation, machine learning, and analytics.
						However, such workflows are not well-served by existing computing capabilities that separate HPC and AI/ML computing paradigms into distinct ecosystems.
						While co-processor accelerators such as GPUs have been successfully applied to both HPC and AI/ML workloads, software stacks, programming languages, and
						programming models are still largely incompatible. Additionally, many scientific machine learning workloads exhibit characteristics that hamper their 
						performance on GPU throughput-oriented architectures. In this talk, we discuss our vision of the codesign process, as well as ongoing efforts at Pacific
						Northwest National Laboratory in codesigning hardware and software stacks to support this notion of convergence and the next generation of scientific computing.
          	  		</p> 
				</div>
            </div>
-->

		</div>
    </section>

    <section id="program" class="section schedule">
        <div class="container">
            <div class="row">
                <div class="col-md-12">
                    <h3 class="section-title">Program:</h3>
					
                    <p>
                    <table class="table table-hover">
                      <thead class="thead-light">
                        <tr>
                          <th colspan=2 scope="col">Sunday June 30<sup>th</sup>, 2024<br><em>(all times are Argentina Local Time (ART))</em></th>
                        </tr>
                      </thead>
                      <tbody>
                        <tr>
                          <th scope="row" class="col-md-3">9:00 - 9:15 AM</th>
                          <td>Introduction and Welcoming Remarks</td>
                        </tr>
                        <tr bgcolor="#EBF5FB">
                          <th scope="row">9:15 - 10:00 AM</th>
                          <td><strong>Invited Talk:</strong> "Modeling and Simulation (ModSim) in the AI Era"<br>
							  Adolfy Hoisie <em>(Brookhaven National Laboratory)</em></td>
                        </tr>
                        <tr>
                          <tr bgcolor="#FEF9E7">
                          <th scope="row">10:00 - 10:20 AM</th>
                          <td>Coffee Break<br>
                        </tr>
                        <tr>
                          <th scope="row">10:20 - 10:50 AM</th>
                          <td>"Artifical Intelligence Governed Processor"<br>
							  Alper Buyuktosunoglu and David Trilla <em>(IBM Research)</em></td>
                        </tr>
                        <tr>
                          <th scope="row">10:50 - 11:20 AM</th>
                          <td>"Efficient FPGA-based power model adaption with Transfer-Learning and Meta-Learning"<br>
							  Zhigang Wei, Aman Arora, Emily Shriver and Lizy John <em> (University of Texas, Austin)</em></td>
                        </tr>
                        <tr bgcolor="#EBF5FB">
                          <th scope="row">11:20 - 12:05 PM</th>
                          <td><strong>Invited Talk:</strong> "Architecture 2.0: From Concept to Breaking Ground"<br>
							  Vijay Janapa Reddi <em>(Harvard University)</em></td>
                        </tr>
                        <th scope="row">12:05 - 12:35 PM</th>
                          <td>"AnGeL: Fully-Automated Analog Circuit Generator Leveraging Neural Networks"<br>
							  Morteza Fayazi, Morteza Tavakoli Taba, Ehsan Afshari and Ronald Dreslinski <em>(University of Michigan)</em></td>
                        </tr>
                        </tr>
                        <tr bgcolor="#FEF9E7">
                          <th scope="row">12:30 - 2:15 PM</th>
                          <td><i>Lunch</i></td>
                        </tr>
                        <tr bgcolor="#EBF5FB">
                          <th scope="row">2:15 - 3:00 PM</th>
                          <td><strong>Invited Talk:</strong> "Scaling Intelligence"<br>
							  Azalia Mirhoseini <em>(Stanford University)</em></td>
                        </tr>
                        <tr bgcolor="#FEF9E7">
                          <th scope="row">3:00 - 3:20 PM</th>
                          <td><i>Break</i></td>
                        </tr>
                          <th scope="row">3:20 - 3:50 PM</th>
                          <td>"FASCINet: A Fully Automated Single-Board Computer Generator Inspired by Neural Networks"<br>
							  Morteza Fayazi, Zachary Colter, Zineb Benameur-El Youbi, Javad Bagherzadeh, Tutu Ajayi and Ronald Dreslinski <em>(University of Michigan)</em></td>
                        </tr>
                        <tr bgcolor="#EBF5FB">
                          <th scope="row">3:50 - 5:00 PM</th>
                          <td><strong>Panel: TBD</strong><br>
						  </td>
                        </tr>						
                        <tr>
                          <th scope="row">5:00 - 5:15 PM</th>
                          <td>Concluding Remarks</td>
                        </tr>
                      </tbody>
                    </table>
                    </p>

                </div>
            </div>
        </div>
    </section>
    -->

    <section id="prev" class="section schedule">
        <div class="container">
            <div class="row">
                <div class="col-md-12">
                    <h3 class="section-title">Past Editions:</h3>
					<ul class="list-arrow-right">
                    <li><a href="https://augustojv.github.io/cogarch-workshop-2023/">2023</a></li>
                    <li><a href="https://augustojv.github.io/cogarch-workshop-2022/">2022</a></li>
                    <li><a href="https://augustojv.github.io/cogarch-workshop-2021/">2021</a></li>
                    <li><a href="https://augustojv.github.io/cogarch-workshop-2020/">2020</a></li>
					<li><a href="https://augustojv.github.io/cogarch-workshop-2018/">2018</a></li>
					</ul>
                </div>
            </div>
        </div>
    </section>


    <section id="org" class="section registration">
        <div class="container">
            <div class="row">
                <div class="col-md-12">
                    <h3 class="section-title">Organizers</h3>
                </div>
				
                <div class="col-md-4">
                <p>
                <b><a href="http://researcher.watson.ibm.com/researcher/view.php?person=us-kvswamin" rel="nofollow" 
		target="_blank">Karthik Swaminathan</a> </b> is a Senior Research Scientist at the IBM T.J Watson Research Center. 
		His research has a broad, cross-layer scope examining circuit, architecture and application level optimizations for 
		improving the reliability and energy efficiency of both general purpose and specialized computing architectures.  He has also worked on characterizing 
		performance and reliability of IBM server-class and mainframe processors at various stages of design. He holds a PhD from the Pennsylvania State University.               </p>
                <p>
                <b><a href="https://www.linkedin.com/in/palsubhankar/" rel="nofollow" target="_blank">Subhankar Pal</a> </b>is a Research Staff Member
				at IBM T. J. Watson Research Center. His research is focused on SoC design methodologies and hardware-software co-design for
				privacy-preserving machine learning. He holds a Ph.D. and M.S. from the University of Michigan. His Ph.D. thesis looked at designing a
				reconfigurable, software-defined hardware solution that balances programmability with energy efficiency. Prior to that, Subhankar was
				with NVIDIA, where he worked on pre-silicon verification and bring-up of multiple generations of GPUs.
                </p>
				</div>
				
                <div class="col-md-4">

                <p>
                <b><a href="https://www.linkedin.com/in/aporvaa/" rel="nofollow" target="_blank">Aporva Amarnath</a> </b>is a Research Scientist at the IBM T. J. Watson
		Research Center. She is interested in developing memory system architectures for emerging applications
		using existing and new memory technologies to tackle the memory wall. Her research interests include,
		developing memory system architectures for emerging applications using existing and new memory
		technologies, creating energy-efficient accelerators for HPC applications and developing schedulers for
		real-time constrained AV applications. She holds a PhD from the University of Michigan.
                </p>
                <p>
                <b><a href="https://anands09.github.io" rel="nofollow" target="_blank">Ananda Samajdar</a> </b>is a Research Staff Member
				at IBM T. J. Watson Research Center working on accelerator design and compilation/mapping strategies for DNN workloads on
				IBM’s RaPiD AI accelerator. He holds a Ph.D. from Georgia Tech.
                </p>
                </div>
                <div id="contact" class="col-md-4">
                    <h4 class="section-title">Contact</h4>
                    <ul class="list-arrow-right">
                    <li><a href="mailto:info@cogarchworkshop.org">info@cogarchworkshop.org</a></li> 
                    </ul>
                </div>
            </div>
        </div>
    </section>

<!--
    <section id="facts" class="section bg-image-1 facts text-center">
        <div class="container">
            <div class="row">
                <div class="col-sm-6">

                    <i class="ion-earth"></i>
                    <h3><a href="http://researcher.watson.ibm.com/researcher/view_group_subpage.php?id=6586" rel="nofollow" target="_blank">CogArch 2015</a></h3>
                
                </div>
                <div class="col-sm-6">

                    <i class="ion-earth"></i>
                    <h3><a href="http://researcher.watson.ibm.com/researcher/view_group.php?id=5848" rel="nofollow" target="_blank">CogArch 2016</h3>
                
                </div>
            </div>
        </div>
    </section>
-->

    <section id="links" class="section bg-image-2 facts ">
        <div class="container">
            <div class="row">
				<div class="col-md-12">
                    <h3 class="section-title">Interesting Links</h3>
                </div>
				<div class="col-md-3">
                    <p>The <a href="http://www.computerhistory.org/timeline/ai-robotics/" target="_blank">AI and Robotics Timeline</a> from 1939 to date</p>
                </div>
				<div class="col-md-3">
                    <p>The <a href="http://research.ibm.com/cognitive-computing/" target="_blank">AI portal</a> with the latest research activities conducted by IBM on AI</p>
                </div>
				<div class="col-md-3">
                    <p>The <a href="https://research.ibm.com/topics/foundation-models" target="_blank">Foundation Models</a> portal</p>
                </div>
				<div class="col-md-3">
                    <p>IBM Watson in action in this <a href="https://www.ibm.com/demos/live/tts-demo/self-service/home" target="_blank">text-to-speech demo</a></p>
                </div>
          </div>
        </div>
    </section>


    <section id="location" class="section location">
        <div class="container">
            <div class="row">
			
				<div id="registration" class="col-md-3">
                    <h3 class="section-title">Registration</h3>

                    <p>
                    CogArch will be held in conjunction with the <b><a href="https://iscaconf.org/isca2024/"  target="_blank">
					51<sup>st</sup> International Symposium on Computer Architecture (ISCA 2024)</a></b>.
                    Refer to the main venue to continue with the registration process.
                    </p>
                </div>


                <div class="col-sm-3">
                    <h3 class="section-title">Event Location</h3>
                    <address>
					  <p>Hilton Buenos Aires<br>
					  Macacha Güemes 351, C1106BKG 
					  Buenos Aires, Argentina
                      </p>
                    </address>
                    
                    <p><b><a href="https://iscaconf.org/isca2024/" target="_blank"> Check main venue site for more information.</a></b></p>

                </div>
                <div class="col-sm-6">
				  <iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d3283.9393725382356!2d-58.3661341236089!3d-34.60569455760355!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x95a335ef4809ceef%3A0x3945c8c351477a54!2sHilton%20Buenos%20Aires!5e0!3m2!1sen!2sus!4v1703095525171!5m2!1sen!2sus" width="600" height="450" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe>
                </div>
            </div>
        </div>
    </section>


    <footer class="site-footer facts">
        <div class="container">
            <div class="row">
                <div class="col-md-12">
                    <p class="site-info">Share this event on your social networks</p>
                </div>
                <div class="col-md-4">
                    <a href="https://twitter.com/home?status=Check%20out%20the%20Workshop%20on%20Cognitive%20Architectures%0Ahttps%3A//cogarchworkshop.org"><i class="ion-social-twitter"></i>&nbsp; Twitter</a>
                </div>
                <div class="col-md-4">
                    <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A//cogarchworkshop.org/"><i class="ion-social-facebook"></i>&nbsp; Facebook</a>
                </div>
                <div class="col-md-4">
                    <a href="https://www.linkedin.com/shareArticle?mini=true&url=https%3A//cogarchworkshop.org/&title=Workshop%20on%20Cognitive%20Architectures&summary=&source="><i class="ion-social-linkedin-outline"></i>&nbsp; LinkedIn</a>
                </div>
            </div>
        </div>
    </footer>

    <!-- script -->
    <script src="bower_components/jquery/dist/jquery.min.js"></script>
    <script src="bower_components/bootstrap/dist/js/bootstrap.min.js"></script>
    <script src="bower_components/smooth-scroll/dist/js/smooth-scroll.min.js"></script>
    <script src="assets/js/main.js"></script>
</body>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-88908704-1', 'auto');
  ga('send', 'pageview');

</script>
  
</html>
